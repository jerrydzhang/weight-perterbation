import numpy as np
import matplotlib.pyplot as plt
import pysindy as ps
from models import WeightedLasso
from utils.ode import lorenz, hydrogen_bromine, hydrogen_bromine_init, map_equation, rober, rober_init
import pandas as pd

from scipy.integrate import solve_ivp

get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")


dt = 0.01
x0_train = hydrogen_bromine_init
# x0_train = [1.28765293e-09, 7.25644133e-10, 1.65047091e-09, 8.16685447e-15, 1.66990500e-08, 1.00000000e-05]
# x0_train = rober_init
# x0_train = [9.99902462e-01, 1.64381452e-05, 8.10998717e-05]
t_train = np.arange(0, 90, dt)
t_train_span = (t_train[0], t_train[-1])

data = solve_ivp(
    hydrogen_bromine,
    t_train_span,
    x0_train,
    method='LSODA',
    rtol=1e-10,
    atol=1e-15,
    t_eval=t_train,
)

X = data.y.T

# print("Generated X shape:", X.shape)
# print("t_train shape:", t_train.shape)

# combined_data = np.c_[t_train, X]
# column_names = ['time', 'x0', 'x1', 'x2']

# # 3. Create a pandas DataFrame
# df = pd.DataFrame(combined_data, columns=column_names)

# # 4. Save the DataFrame to a CSV file
# # index=False prevents pandas from writing the DataFrame index as a column
# df.to_csv('rober_ode_skip_stiff.csv', index=False)





print(X[1000])


import matplotlib.pyplot as plt

for i in range(X.shape[1]):
    plt.figure(figsize=(10, 5))
    # plt.plot(t_train, X[:, i], label=f"Dimension {i+1}", lw=0.5)
    plt.plot(data.t, X[:, i], label=f"Dimension {i+1}", lw=0.5)
    plt.xlabel("Time")
    plt.ylabel(f"Trajectory Value (X{i+1})")
    plt.title(f"ODE Trajectory for Dimension {i+1}")
    plt.legend()
    plt.show()


fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')
ax.plot(X[:,0], X[:,1], X[:,2], lw=0.5)
ax.set_xlabel("X")
ax.set_ylabel("Y")
ax.set_zlabel("Z")
ax.set_title("Lorenz System 3D Trajectory")
plt.show()


# hydrogen_bromine(t_train, X.T), t_train.shape, X.shape
# for row in hydrogen_bromine(t_train, X.T):
#     print(len(row), row.shape)
# t_train.shape, X.shape


library = ps.PolynomialLibrary(degree=3)
library.fit(X)
true_coef = map_equation(hydrogen_bromine, library).T
model = ps.SINDy(
    feature_library=library,
    # optimizer=WeightedLasso(alpha=1e-4, weights=np.ones((library.size, 6)), max_iter=10000),
    optimizer=WeightedLasso(alpha=1e-4, weights=1/(np.abs(true_coef) + 1e-10), max_iter=10000),
    differentiation_method=ps.FiniteDifference(),
)


model.fit(x=X, t=t_train, x_dot=np.asarray(hydrogen_bromine(t_train, X.T)).T)
model.print()


print(ps.__version__)


library.n_output_features_


model.coefficients()


true_coef = map_equation(hydrogen_bromine, library)
pred_coef = model.coefficients()

plt.figure(figsize=(10, 5))
plt.subplot(3, 1, 1)
plt.imshow(true_coef, cmap='viridis', aspect='auto')
plt.title("True Coefficients")
plt.subplot(3, 1, 2)
plt.imshow(pred_coef, cmap='viridis', aspect='auto')
plt.title("Predicted Coefficients")
plt.subplot(3, 1, 3)
plt.imshow(np.abs(true_coef - pred_coef), cmap='viridis', aspect='auto')
plt.title("Absolute Error")
plt.colorbar()
plt.tight_layout()
plt.show()



plt.figure(figsize=(10, 5))
for row in range(true_coef.shape[0]):
    plt.scatter(
        np.arange(true_coef.shape[1]),
        true_coef[row, :],
        label=f"True Coefficients Row {row}",
        alpha=0.5,
    )

plt.yscale('symlog')
plt.show()


import matplotlib.colors as colors

# true_coef = map_equation(rober, library)
true_coef = map_equation(hydrogen_bromine, library)
# pred_coef = model.coefficients()

# plt.figure(figsize=(10, 5))
# plt.subplot(3, 1, 1)
# plt.imshow(true_coef, cmap='viridis', aspect='auto')
# plt.title("True Coefficients")
# plt.subplot(3, 1, 2)
# plt.imshow(pred_coef, cmap='viridis', aspect='auto')
# plt.title("Predicted Coefficients")
# plt.subplot(3, 1, 3)
# plt.imshow(np.abs(true_coef - pred_coef), cmap='viridis', aspect='auto')
# plt.title("Absolute Error")
# plt.colorbar()
# plt.tight_layout()
# plt.show()

learned_coefficients = model.coefficients()
# learned_coefficients[np.abs(learned_coefficients) < 1e-4] = 0.0
# true_parameters[np.abs(true_parameters) < 1e-4] = 0.0 # Also clean true params for fairness

# Reshape from 1D vector (100,) to 2D column vector (100, 1) for imshow
# true_params_2d = true_parameters.reshape(-1, 1)
# learned_coeffs_2d = learned_coefficients.reshape(-1, 1)


# --- 3. Set up Shared Color Scale ---
# Find the maximum absolute value across BOTH arrays to center the color map
abs_max = max(np.abs(true_coef).max(), np.abs(learned_coefficients).max())

# Set vmin and vmax to be symmetric around zero.
vmin = -abs_max
vmax = abs_max

# Create the symmetric log normalizer
# linthresh: The range within which the plot is linear (-linthresh to +linthresh)
# A smaller value makes the log scale apply to smaller numbers.
linthresh = 1e-2
log_norm = colors.SymLogNorm(linthresh=linthresh, vmin=vmin, vmax=vmax, base=10)


# --- 4. Plotting ---
fig, ax = plt.subplots(1, 2, figsize=(16, 7))
fig.suptitle('Comparison of True and Learned Coefficients (Log Scale)', fontsize=16)

# Plot True Parameters
im1 = ax[0].imshow(
    true_coef,
    aspect='auto',
    cmap='coolwarm',
    norm=log_norm  # Apply the shared log normalization
)
ax[0].set_title('True Parameters')
ax[0].set_xlabel('Parameter Index')
ax[0].set_ylabel('Equation')
# ax[0].set_xticks([]) # Hide x-axis ticks as they are not meaningful

# Plot Learned Parameters
im2 = ax[1].imshow(
    learned_coefficients,
    aspect='auto',
    cmap='coolwarm',
    norm=log_norm  # Apply the SAME shared log normalization
)
ax[1].set_title('Learned Parameters')
ax[1].set_xlabel('Parameter Index')
# ax[1].set_xticks([])
# ax[1].set_yticks([]) # Hide y-axis ticks for the second plot

# Add a single, shared colorbar
fig.colorbar(im2, ax=ax, orientation='vertical', label='Coefficient Value (Log Scale)', shrink=0.7)

# plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust for suptitle
# plt.show()
# plt.savefig('true_vs_learned_coefficients.png')


simulated_data = model.simulate(X[0], t_train)


for i in range(X.shape[1]):
    plt.figure(figsize=(10, 5))
    # plt.plot(t_train, X[:, i], label=f"Dimension {i+1}", lw=0.5)
    plt.plot(data.t, X[:, i], label=f"True {i+1}", lw=0.5)
    plt.plot(t_train, simulated_data[:, i], label=f"Simulated {i+1}", lw=0.5, linestyle='--')
    plt.xlabel("Time")
    plt.ylabel(f"Trajectory Value (X{i+1})")
    plt.yscale('log')  # Use log scale for better visibility
    plt.title(f"ODE Trajectory for Dimension {i+1}")
    plt.legend()
    # plt.show()
    plt.savefig(f'trajectory_dimension_{i+1}.png')






